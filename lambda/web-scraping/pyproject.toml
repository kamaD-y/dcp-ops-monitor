[project]
name = "web-scraping"
version = "0.1.0"
description = "To check the operation status of defined contribution pension plans, scrape web pages and provide summary information."
readme = "README.md"
requires-python = ">=3.13.1"
dependencies = [
    "shared",
    "selenium>=4.33.0",
    "gspread>=6.0.0",
    "google-auth>=2.0.0",
]

[tool.uv.sources]
shared = { workspace = true }

[dependency-groups]
dev = [
    "botocore[crt]>=1.42.13",
    "pytest>=8.3.5",
    "pytest-cov>=6.2.1",
    "pytest-env>=1.1.5",
    "pytest-mock>=3.14.0",
    "python-dotenv>=1.1.0",
    "ruff>=0.11.8",
    "testcontainers>=4.10.0",
]

[tool.ruff]
extend = "../../pyproject.toml"

[tool.pytest.ini_options]
pythonpath = ["src/../", "src"]
testpaths = ["tests",]
env = [
    "ENV=test",
    "SCRAPING_PARAMETER_NAME=/test/scraping-parameters",
    "DATA_BUCKET_NAME=test-data-bucket"
]

[tool.coverage.run]
source = ["src"]
omit = ["tests/*", "*/test_*"]

[tool.coverage.report]
fail_under = 40 # TODO: 一時的に設定
